torch.linalg.matrix_norm(A, ord='fro', dim=(-2, -1), keepdim=False, *, dtype=None, out=None)
torch.linalg.vector_norm(A, ord=2, dim=None, keepdim=False, *, dtype=None, out=None)
torch.linalg.eigh(A, UPLO='L', *, out=None)
torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.linalg.matrix_rank(A, tol=None, hermitian=False, *, out=None)
torch.linalg.householder_product(A, tau, *, out=None)
torch.linalg.slogdet(A, *, out=None)
torch.linalg.pinv(A, rcond=1e-15, hermitian=False, *, out=None)
torch.linalg.matrix_power(A, n, *, out=None)
torch.linalg.matmul(input, other, *, out=None)
torch.linalg.det(A, *, out=None)
torch.linalg.eigh(A, UPLO='L', *, out=None)
torch.linalg.solve(A, B, *, out=None)
torch.linalg.tensorinv(A, ind=2, *, out=None)
torch.linalg.tensorsolve(A, B, dims=None, *, out=None)
torch.linalg.norm(A, ord=None, dim=None, keepdim=False, *, out=None, dtype=None)
torch.linalg.inv_ex(A, *, check_errors=False, out=None)
torch.linalg.inv(A, *, out=None)
torch.linalg.cholesky_ex(A, *, upper=False, check_errors=False, out=None)
torch.linalg.qr(A, mode='reduced', *, out=None)
torch.linalg.eig(A, *, out=None)
torch.linalg.cholesky(A, *, upper=False, out=None)
torch.linalg.multi_dot(tensors, *, out=None)
torch.nn.functional.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)
torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)
torch.nn.functional.conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)
torch.nn.functional.conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1)
torch.nn.functional.conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1)
torch.nn.functional.conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1)
torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)
torch.nn.functional.fold(input, output_size, kernel_size, dilation=1, padding=0, stride=1)
torch.nn.functional.avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
torch.nn.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.functional.avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.functional.max_pool3d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.functional.max_unpool1d(input, indices, kernel_size, stride=None, padding=0, output_size=None)
torch.nn.functional.max_unpool2d(input, indices, kernel_size, stride=None, padding=0, output_size=None)
torch.nn.functional.max_unpool3d(input, indices, kernel_size, stride=None, padding=0, output_size=None)
torch.nn.functional.lp_pool1d(input, norm_type, kernel_size, stride=None, ceil_mode=False)
torch.nn.functional.lp_pool2d(input, norm_type, kernel_size, stride=None, ceil_mode=False)
torch.nn.functional.adaptive_max_pool1d(input, output_size, return_indices=False)
torch.nn.functional.adaptive_max_pool2d(input, output_size, return_indices=False)
torch.nn.functional.adaptive_max_pool3d(input, output_size, return_indices=False)
torch.nn.functional.adaptive_avg_pool1d(input, output_size)
torch.nn.functional.adaptive_avg_pool2d(input, output_size)
torch.nn.functional.adaptive_avg_pool3d(input, output_size)
torch.nn.functional.threshold(input, threshold, value, inplace=False)
torch.nn.functional.threshold_(input, threshold, value)
torch.nn.functional.relu(input, inplace=False)
torch.nn.functional.relu_(input)
torch.nn.functional.hardtanh(input, min_val=-1., max_val=1., inplace=False)
torch.nn.functional.hardtanh_(input, min_val=-1., max_val=1.)
torch.nn.functional.hardswish(input, inplace=False)
torch.nn.functional.relu6(input, inplace=False)
torch.nn.functional.elu(input, alpha=1.0, inplace=False)
torch.nn.functional.elu_(input, alpha=1.)
torch.nn.functional.selu(input, inplace=False)
torch.nn.functional.celu(input, alpha=1., inplace=False)
torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False)
torch.nn.functional.leaky_relu_(input, negative_slope=0.01)
torch.nn.functional.prelu(input, weight)
torch.nn.functional.rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False)
torch.nn.functional.rrelu_(input, lower=1./8, upper=1./3, training=False)
torch.nn.functional.glu(input, dim=-1)
torch.nn.functional.gelu(input)
torch.nn.functional.logsigmoid(input)
torch.nn.functional.hardshrink(input, lambd=0.5)
torch.nn.functional.tanhshrink(input)
torch.nn.functional.softsign(input)
torch.nn.functional.softplus(input, beta=1, threshold=20)
torch.nn.functional.softmin(input, dim=None, _stacklevel=3, dtype=None)
torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None)
torch.nn.functional.softshrink(input, lambd=0.5)
torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1)
torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)
torch.nn.functional.tanh(input)
torch.nn.functional.sigmoid(input)
torch.nn.functional.hardsigmoid(input, inplace=False)
torch.nn.functional.silu(input, inplace=False)
torch.nn.functional.batch_norm(input, running_mean, running_var, weight=None, bias=None, training=False, momentum=0.1, eps=1e-05)
torch.nn.functional.instance_norm(input, running_mean=None, running_var=None, weight=None, bias=None, use_input_stats=True, momentum=0.1, eps=1e-05)
torch.nn.functional.layer_norm(input, normalized_shape, weight=None, bias=None, eps=1e-05)
torch.nn.functional.local_response_norm(input, size, alpha=0.0001, beta=0.75, k=1.0)
torch.nn.functional.normalize(input, p=2.0, dim=1, eps=1e-12, out=None)
torch.nn.functional.linear(input, weight, bias=None)
torch.nn.functional.bilinear(input1, input2, weight, bias=None)
torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False)
torch.nn.functional.alpha_dropout(input, p=0.5, training=False, inplace=False)
torch.nn.functional.feature_alpha_dropout(input, p=0.5, training=False, inplace=False)
torch.nn.functional.dropout2d(input, p=0.5, training=True, inplace=False)
torch.nn.functional.dropout3d(input, p=0.5, training=True, inplace=False)
torch.nn.functional.embedding(input, weight, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None, include_last_offset=False, padding_idx=None)
torch.nn.functional.one_hot(tensor, num_classes=-1)
torch.nn.functional.pairwise_distance(x1, x2, p=2.0, eps=1e-06, keepdim=False)
torch.nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8)
torch.nn.functional.pdist(input, p=2)
torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)
torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')
torch.nn.functional.cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean', zero_infinity=False)
torch.nn.functional.hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.kl_div(input, target, size_average=None, reduce=None, reduction='mean', log_target=False)
torch.nn.functional.l1_loss(input, target, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.multilabel_soft_margin_loss(input, target, weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.multi_margin_loss(input, target, p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
torch.nn.functional.smooth_l1_loss(input, target, size_average=None, reduce=None, reduction='mean', beta=1.0)
torch.nn.functional.soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.triplet_margin_loss(anchor, positive, negative, margin=1.0, p=2, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')
torch.nn.functional.triplet_margin_with_distance_loss(anchor, positive, negative, *, distance_function=None, margin=1.0, swap=False, reduction='mean')
torch.nn.functional.pixel_shuffle(input, upscale_factor)
torch.nn.functional.pixel_unshuffle(input, downscale_factor)
torch.nn.functional.pad(input, pad, mode='constant', value=0)
torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)
torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.nn.functional.upsample_nearest(input, size=None, scale_factor=None)
torch.nn.functional.upsample_bilinear(input, size=None, scale_factor=None)
torch.nn.functional.grid_sample(input, grid, mode='bilinear', padding_mode='zeros', align_corners=None)
torch.nn.functional.affine_grid(theta, size, align_corners=None)
torch.is_tensor(obj)
torch.is_storage(obj)
torch.is_complex(input)
torch.is_floating_point(input)
torch.is_nonzero(input)
torch.set_default_dtype(d)
torch.get_default_dtype()
torch.set_default_tensor_type(t)
torch.numel(input)
torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)
torch.set_flush_denormal(mode)
torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.randint_like(input, low=0, high, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.randperm(n, *, generator=None, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False, pin_memory=False)
torch.empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False, memory_format=torch.contiguous_format)
torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False)
torch.sparse_coo_tensor(indices, values, size=None, *, dtype=None, device=None, requires_grad=False)
torch.as_tensor(data, dtype=None, device=None)
torch.as_strided(input, size, stride, storage_offset=0)
torch.from_numpy(ndarray)
torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.range(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.logspace(start, end, steps, base=10.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.empty_strided(size, stride, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False)
torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.full_like(input, fill_value, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.quantize_per_tensor(input, scale, zero_point, dtype)
torch.quantize_per_channel(input, scales, zero_points, axis, dtype)
torch.dequantize(tensor)
torch.dequantize(tensors)
torch.complex(real, imag, *, out=None)
torch.imag(input)
torch.polar(abs, angle, *, out=None)
torch.angle(input, *, out=None)
torch.heaviside(input, values, *, out=None)
torch.cat(tensors, dim=0, *, out=None)
torch.concat(tensors, dim=0, *, out=None)
torch.chunk(input, chunks, dim=0)
torch.column_stack(tensors, *, out=None)
torch.dstack(tensors, *, out=None)
torch.gather(input, dim, index, *, sparse_grad=False, out=None)
torch.hstack(tensors, *, out=None)
torch.index_select(input, dim, index, *, out=None)
torch.masked_select(input, mask, *, out=None)
torch.movedim(input, source, destination)
torch.moveaxis(input, source, destination)
torch.narrow(input, dim, start, length)
torch.nonzero(input, *, out=None, as_tuple=False)
torch.reshape(input, shape)
torch.row_stack(tensors, *, out=None)
torch.vstack(tensors, *, out=None)
torch.scatter(input, dim, index, src)
torch.scatter_add(input, dim, index, src)
torch.split(tensor, split_size_or_sections, dim=0)
torch.squeeze(input, dim=None, *, out=None)
torch.stack(tensors, dim=0, *, out=None)
torch.swapaxes(input, axis0, axis1)
torch.transpose(input, dim0, dim1)
torch.swapdims(input, dim0, dim1)
torch.t(input)
torch.take(input, index)
torch.tensor_split(input, indices_or_sections, dim=0)
torch.tile(input, reps)
torch.unbind(input, dim=0)
torch.unsqueeze(input, dim)
torch.where(condition, x, y)
torch.Generator(device='cpu')
torch.seed()
torch.manual_seed(seed)
torch.initial_seed()
torch.get_rng_state()
torch.set_rng_state(new_state)
torch.bernoulli(input, *, generator=None, out=None)
torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None)
torch.normal(mean, std, size, *, out=None)
torch.poisson(input, generator=None)
torch.quasirandom.SobolEngine(dimension, scramble=False, seed=None)
torch.get_num_threads()
torch.set_num_threads(int)
torch.get_num_interop_threads()
torch.set_num_interop_threads(int)
torch.set_grad_enabled(mode)
torch.abs(input, *, out=None)
torch.absolute(input, *, out=None)
torch.acos(input, *, out=None)
torch.arccos(input, *, out=None)
torch.acosh(input, *, out=None)
torch.arccosh(input, *, out=None)
torch.add(input, other, *, alpha=1, out=None)
torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None)
torch.addcmul(input, tensor1, tensor2, *, value=1, out=None)
torch.asin(input, *, out=None)
torch.arcsin(input, *, out=None)
torch.asinh(input, *, out=None)
torch.arcsinh(input, *, out=None)
torch.atan(input, *, out=None)
torch.arctan(input, *, out=None)
torch.atanh(input, *, out=None)
torch.arctanh(input, *, out=None)
torch.atan2(input, other, *, out=None)
torch.bitwise_not(input, *, out=None)
torch.bitwise_and(input, other, *, out=None)
torch.bitwise_or(input, other, *, out=None)
torch.bitwise_xor(input, other, *, out=None)
torch.ceil(input, *, out=None)
torch.clamp(input, min=None, max=None, *, out=None)
torch.max(input, dim, keepdim=False, *, out=None)
torch.clip(input, min=None, max=None, *, out=None)
torch.conj(input)
torch.copysign(input, other, *, out=None)
torch.cos(input, *, out=None)
torch.cosh(input, *, out=None)
torch.deg2rad(input, *, out=None)
torch.div(input, other, *, rounding_mode=None, out=None)
torch.divide(input, other, *, rounding_mode=None, out=None)
torch.digamma(input, *, out=None)
torch.erf(input, *, out=None)
torch.erfc(input, *, out=None)
torch.erfinv(input, *, out=None)
torch.exp(input, *, out=None)
torch.exp2(input, *, out=None)
torch.expm1(input, *, out=None)
torch.fake_quantize_per_channel_affine(input, scale, zero_point, quant_min, quant_max)
torch.fake_quantize_per_tensor_affine(input, scale, zero_point, quant_min, quant_max)
torch.fix(input, *, out=None)
torch.trunc(input, *, out=None)
torch.float_power(input, exponent, *, out=None)
torch.floor(input, *, out=None)
torch.floor_divide(input, other, *, out=None)
torch.fmod(input, other, *, out=None)
torch.frac(input, *, out=None)
torch.ldexp(input, other, *, out=None)
torch.lerp(input, end, weight, *, out=None)
torch.lgamma(input, *, out=None)
torch.log(input, *, out=None)
torch.log10(input, *, out=None)
torch.log1p(input, *, out=None)
torch.log2(input, *, out=None)
torch.logaddexp(input, other, *, out=None)
torch.logaddexp2(input, other, *, out=None)
torch.logical_and(input, other, *, out=None)
torch.logical_not(input, *, out=None)
torch.logical_or(input, other, *, out=None)
torch.logical_xor(input, other, *, out=None)
torch.logit(input, eps=None, *, out=None)
torch.hypot(input, other, *, out=None)
torch.i0(input, *, out=None)
torch.igamma(input, other, *, out=None)
torch.igammac(input, other, *, out=None)
torch.mul(input, other, *, out=None)
torch.multiply(input, other, *, out=None)
torch.mvlgamma(input, p)
torch.nan_to_num(input, nan=0.0, posinf=None, neginf=None, *, out=None)
torch.neg(input, *, out=None)
torch.negative(input, *, out=None)
torch.nextafter(input, other, *, out=None)
torch.polygamma(n, input, *, out=None)
torch.pow(input, exponent, *, out=None)
torch.rad2deg(input, *, out=None)
torch.real(input)
torch.reciprocal(input, *, out=None)
torch.remainder(input, other, *, out=None)
torch.round(input, *, out=None)
torch.rsqrt(input, *, out=None)
torch.sigmoid(input, *, out=None)
torch.sign(input, *, out=None)
torch.sgn(input, *, out=None)
torch.signbit(input, *, out=None)
torch.sin(input, *, out=None)
torch.sinc(input, *, out=None)
torch.sinh(input, *, out=None)
torch.sqrt(input, *, out=None)
torch.square(input, *, out=None)
torch.sub(input, other, *, alpha=1, out=None)
torch.subtract(input, other, *, alpha=1, out=None)
torch.tan(input, *, out=None)
torch.tanh(input, *, out=None)
torch.true_divide(dividend, divisor, *, out)
torch.xlogy(input, other, *, out=None)
torch.argmax(input, dim, keepdim=False)
torch.argmin(input, dim=None, keepdim=False)
torch.amax(input, dim, keepdim=False, *, out=None)
torch.amin(input, dim, keepdim=False, *, out=None)
torch.all(input, dim, keepdim=False, *, out=None)
torch.any(input, dim, keepdim=False, *, out=None)
torch.min(input, dim, keepdim=False, *, out=None)
torch.dist(input, other, p=2)
torch.logsumexp(input, dim, keepdim=False, *, out=None)
torch.mean(input, dim, keepdim=False, *, dtype=None)
torch.median(input, dim=-1, keepdim=False, *, out=None)
torch.nanmedian(input, dim=-1, keepdim=False, *, out=None)
torch.mode(input, dim=-1, keepdim=False, *, out=None)
torch.norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)
torch.nansum(input, dim, keepdim=False, *, dtype=None)
torch.prod(input, dim, keepdim=False, *, dtype=None)
torch.quantile(input, q, dim=None, keepdim=False, *, out=None)
torch.nanquantile(input, q, dim=None, keepdim=False, *, out=None)
torch.std(input, dim, unbiased, keepdim=False, *, out=None)
torch.std_mean(input, dim, unbiased, keepdim=False, *, out=None)
torch.sum(input, dim, keepdim=False, *, dtype=None)
torch.unique(input, sorted=True, return_inverse=False, return_counts=False, dim=None)
torch.unique_consecutive(input, return_inverse=False, return_counts=False, dim=None)
torch.var(input, dim, unbiased, keepdim=False, *, out=None)
torch.var_mean(input, dim, unbiased, keepdim=False, *, out=None)
torctorch.repeat_interleaveh.count_nonzero(input, dim=None)
torch.allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False)
torch.argsort(input, dim=-1, descending=False)
torch.eq(input, other, *, out=None)
torch.equal(input, other)
torch.ge(input, other, *, out=None)
torch.greater_equal(input, other, *, out=None)
torch.gt(input, other, *, out=None)
torch.greater(input, other, *, out=None)
torch.isclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False)
torch.isfinite(input)
torch.isinf(input)
torch.isposinf(input, *, out=None)
torch.isneginf(input, *, out=None)
torch.isnan(input)
torch.isreal(input)
torch.kthvalue(input, k, dim=None, keepdim=False, *, out=None)
torch.le(input, other, *, out=None)
torch.less_equal(input, other, *, out=None)
torch.lt(input, other, *, out=None)
torch.less(input, other, *, out=None)
torch.maximum(input, other, *, out=None)
torch.minimum(input, other, *, out=None)
torch.fmax(input, other, *, out=None)
torch.fmin(input, other, *, out=None)
torch.ne(input, other, *, out=None)
torch.not_equal(input, other, *, out=None)
torch.sort(input, dim=-1, descending=False, stable=False, *, out=None)
torch.topk(input, k, dim=None, largest=True, sorted=True, *, out=None)
torch.msort(input, *, out=None)
torch.stft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=None, return_complex=None)
torch.istft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, normalized=False, onesided=None, length=None, return_complex=False)
torch.bartlett_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.blackman_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.hamming_window(window_length, periodic=True, alpha=0.54, beta=0.46, *, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.hann_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.kaiser_window(window_length, periodic=True, beta=12.0, *, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.atleast_1d(*tensors)
torch.atleast_2d(*tensors)
torch.atleast_3d(*tensors)
torch.bincount(input, weights=None, minlength=0)
torch.block_diag(*tensors)
torch.broadcast_tensors(*tensors)
torch.broadcast_to(input, shape)
torch.broadcast_shapes(*shapes)
torch.bucketize(input, boundaries, *, out_int32=False, right=False, out=None)
torch.cartesian_prod(*tensors)
torch.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')
torch.clone(input, *, memory_format=torch.preserve_format)
torch.combinations(input, r=2, with_replacement=False)
torch.cross(input, other, dim=None, *, out=None)
torch.cummax(input, dim, *, out=None)
torch.cummin(input, dim, *, out=None)
torch.cumprod(input, dim, *, dtype=None, out=None)
torch.cumsum(input, dim, *, dtype=None, out=None)
torch.diag(input, diagonal=0, *, out=None)
torch.diag_embed(input, offset=0, dim1=-2, dim2=-1)
torch.diagflat(input, offset=0)
torch.diagonal(input, offset=0, dim1=0, dim2=1)
torch.diff(input, n=1, dim=-1, prepend=None, append=None)
torch.einsum(equation, *operands)
torch.flatten(input, start_dim=0, end_dim=-1)
torch.flip(input, dims)
torch.fliplr(input)
torch.flipud(input)
torch.kron(input, other, *, out=None)
torch.rot90(input, k, dims)
torch.gcd(input, other, *, out=None)
torch.histc(input, bins=100, min=0, max=0, *, out=None)
torch.meshgrid(*tensors)
torch.lcm(input, other, *, out=None)
torch.logcumsumexp(input, dim, *, out=None)
torch.ravel(input)
torch.renorm(input, p, dim, maxnorm, *, out=None)
torch.repeat_interleave(input, repeats, dim=None)
torch.roll(input, shifts, dims=None)
torch.searchsorted(sorted_sequence, values, *, out_int32=False, right=False, out=None)
torch.tensordot(a, b, dims=2, out=None)
torch.trace(input)
torch.tril(input, diagonal=0, *, out=None)
torch.tril_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided)
torch.triu(input, diagonal=0, *, out=None)
torch.triu_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided)
torch.vander(x, N=None, increasing=False)
torch.view_as_real(input)
torch.view_as_complex(input)
torch.addbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None)
torch.addmm(input, mat1, mat2, *, beta=1, alpha=1, out=None)
torch.addmv(input, mat, vec, *, beta=1, alpha=1, out=None)
torch.addr(input, vec1, vec2, *, beta=1, alpha=1, out=None)
torch.baddbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None)
torch.bmm(input, mat2, *, deterministic=False, out=None)
torch.chain_matmul(*matrices, out=None)
torch.cholesky(input, upper=False, *, out=None)
torch.cholesky_inverse(input, upper=False, *, out=None)
torch.cholesky_solve(input, input2, upper=False, *, out=None)
torch.dot(input, other, *, out=None)
torch.eig(input, eigenvectors=False, *, out=None)
torch.geqrf(input, *, out=None)
torch.ger(input, vec2, *, out=None)
torch.outer(input, vec2, *, out=None)
torch.inner(input, other, *, out=None)
torch.inverse(input, *, out=None)
torch.det(input)
torch.logdet(input)
torch.slogdet(input)
torch.lstsq(input, A, *, out=None)
torch.lu(A, pivot=True, get_infos=False, *, out=None)
torch.lu_solve(b, LU_data, LU_pivots, *, out=None)
torch.lu_unpack(LU_data, LU_pivots, unpack_data=True, unpack_pivots=True, *, out=None)
torch.matmul(input, other, *, out=None)
torch.matrix_power(input, n, *, out=None)
torch.matrix_rank(input, tol=None, symmetric=False, *, out=None)
torch.matrix_exp(input)
torch.mm(input, mat2, *, out=None)
torch.mv(input, vec, *, out=None)
torch.orgqr(input, tau)
torch.ormqr(input, tau, other, left=True, transpose=False, *, out=None)
torch.pinverse(input, rcond=1e-15)
torch.qr(input, some=True, *, out=None)
torch.solve(input, A, *, out=None)
torch.svd(input, some=True, compute_uv=True, *, out=None)
torch.svd_lowrank(A, q=6, niter=2, M=None)
torch.pca_lowrank(A, q=None, center=True, niter=2)
torch.symeig(input, eigenvectors=False, upper=True, *, out=None)
torch.lobpcg(A, k=None, B=None, X=None, n=None, iK=None, niter=None, tol=None, largest=None, method=None, tracker=None, ortho_iparams=None, ortho_fparams=None, ortho_bparams=None)
torch.trapz(y, x, *, dim=-1)
torch.trapz(y, *, dx=1, dim=-1)
torch.triangular_solve(b, A, upper=True, transpose=False, unitriangular=False)
torch.vdot(input, other, *, out=None)
torch.compiled_with_cxx11_abi()
torch.result_type(tensor1, tensor2)
torch.can_cast(from, to)
torch.promote_types(type1, type2)
torch.use_deterministic_algorithms(mode)
torch.are_deterministic_algorithms_enabled()
torch._assert(condition, message)
torch.nn.Sequential(*args)
torch.nn.ModuleList(modules=None)
torch.nn.ModuleDict(modules=None)
torch.nn.ParameterList(parameters=None)
torch.nn.ParameterDict(parameters=None)
torch.nn.modules.module.register_module_forward_pre_hook(hook)
torch.nn.modules.module.register_module_forward_hook(hook)
torch.nn.modules.module.register_module_backward_hook(hook)
torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConv1d(out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConv2d(out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConv3d(out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConvTranspose1d(out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConvTranspose2d(out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.LazyConvTranspose3d(out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)
torch.nn.Fold(output_size, kernel_size, dilation=1, padding=0, stride=1)
torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0)
torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)
torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0)
torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.FractionalMaxPool2d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None)
torch.nn.LPPool1d(norm_type, kernel_size, stride=None, ceil_mode=False)
torch.nn.LPPool2d(norm_type, kernel_size, stride=None, ceil_mode=False)
torch.nn.AdaptiveMaxPool1d(output_size, return_indices=False)
torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False)
torch.nn.AdaptiveMaxPool3d(output_size, return_indices=False)
torch.nn.AdaptiveAvgPool1d(output_size)
torch.nn.AdaptiveAvgPool2d(output_size)
torch.nn.AdaptiveAvgPool3d(output_size)
torch.nn.ReflectionPad1d(padding)
torch.nn.ReflectionPad2d(padding)
torch.nn.ReplicationPad1d(padding)
torch.nn.ReplicationPad2d(padding)
torch.nn.ReplicationPad3d(padding)
torch.nn.ZeroPad2d(padding)
torch.nn.ConstantPad1d(padding, value)
torch.nn.ConstantPad2d(padding, value)
torch.nn.ConstantPad3d(padding, value)
torch.nn.ELU(alpha=1.0, inplace=False)
torch.nn.Hardshrink(lambd=0.5)
torch.nn.Hardsigmoid(inplace=False)
torch.nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False, min_value=None, max_value=None)
torch.nn.Hardswish(inplace=False)
torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)
torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None)
torch.nn.PReLU(num_parameters=1, init=0.25, device=None, dtype=None)
torch.nn.ReLU(inplace=False)
torch.nn.ReLU6(inplace=False)
torch.nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=False)
torch.nn.SELU(inplace=False)
torch.nn.CELU(alpha=1.0, inplace=False)
torch.nn.SiLU(inplace=False)
torch.nn.Softplus(beta=1, threshold=20)
torch.nn.Softshrink(lambd=0.5)
torch.nn.Threshold(threshold, value, inplace=False)
torch.nn.Softmin(dim=None)
torch.nn.Softmax(dim=None)
torch.nn.LogSoftmax(dim=None)
torch.nn.AdaptiveLogSoftmaxWithLoss(in_features, n_classes, cutoffs, div_value=4.0, head_bias=False, device=None, dtype=None)
torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)
torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, process_group=None, device=None, dtype=None)
torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)
torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)
torch.nn.InstanceNorm3d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None)
torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True, device=None, dtype=None)
torch.nn.LocalResponseNorm(size, alpha=0.0001, beta=0.75, k=1.0)
torch.nn.RNNBase(mode, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)
torch.nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='tanh', bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)
torch.nn.LSTM(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)
torch.nn.GRU(input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, device=None, dtype=None)
torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', device=None, dtype=None)
torch.nn.LSTMCell(input_size, hidden_size, bias=True, device=None, dtype=None)
torch.nn.GRUCell(input_size, hidden_size, bias=True, device=None, dtype=None)
torch.nn.Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation='relu', custom_encoder=None, custom_decoder=None, layer_norm_eps=1e-05, batch_first=False, device=None, dtype=None)
torch.nn.TransformerEncoder(encoder_layer, num_layers, norm=None)
torch.nn.TransformerDecoder(decoder_layer, num_layers, norm=None)
torch.nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu', layer_norm_eps=1e-05, batch_first=False, device=None, dtype=None)
torch.nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu', layer_norm_eps=1e-05, batch_first=False, device=None, dtype=None)
torch.nn.Identity(*args, **kwargs)
torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)
torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True, device=None, dtype=None)
torch.nn.LazyLinear(out_features, bias=True, device=None, dtype=None)
torch.nn.Dropout(p=0.5, inplace=False)
torch.nn.Dropout2d(p=0.5, inplace=False)
torch.nn.Dropout3d(p=0.5, inplace=False)
torch.nn.AlphaDropout(p=0.5, inplace=False)
torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None)
torch.nn.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, device=None, dtype=None)
torch.nn.CosineSimilarity(dim=1, eps=1e-08)
torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)
torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')
torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')
torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
torch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)
torch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')
torch.nn.GaussianNLLLoss(*, full=False, eps=1e-06, reduction='mean')
torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean', log_target=False)
torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)
torch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')
torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')
torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')
torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean', beta=1.0)
torch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction='mean')
torch.nn.MultiLabelSoftMarginLoss(weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')
torch.nn.MultiMarginLoss(p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')
torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')
torch.nn.TripletMarginWithDistanceLoss(*, distance_function=None, margin=1.0, swap=False, reduction='mean')
torch.nn.PixelShuffle(upscale_factor)
torch.nn.PixelUnshuffle(downscale_factor)
torch.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.nn.UpsamplingNearest2d(size=None, scale_factor=None)
torch.nn.UpsamplingBilinear2d(size=None, scale_factor=None)
torch.nn.ChannelShuffle(groups)
torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)
torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0, broadcast_buffers=True, process_group=None, bucket_cap_mb=25, find_unused_parameters=False, check_reduction=False, gradient_as_bucket_view=False)
torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2.0, error_if_nonfinite=False)
torch.nn.utils.clip_grad_value_(parameters, clip_value)
torch.nn.utils.parameters_to_vector(parameters)
torch.nn.utils.vector_to_parameters(vec, parameters)
torch.nn.utils.prune.PruningContainer(*args)
torch.nn.utils.prune.RandomUnstructured(amount)
torch.nn.utils.prune.L1Unstructured(amount)
torch.nn.utils.prune.RandomStructured(amount, dim=-1)
torch.nn.utils.prune.LnStructured(amount, n, dim=-1)
torch.nn.utils.prune.CustomFromMask(mask)
torch.nn.utils.prune.random_unstructured(module, name, amount)
torch.nn.utils.prune.l1_unstructured(module, name, amount, importance_scores=None)
torch.nn.utils.prune.random_structured(module, name, amount, dim)
torch.nn.utils.prune.ln_structured(module, name, amount, n, dim, importance_scores=None)
torch.nn.utils.prune.global_unstructured(parameters, pruning_method, importance_scores=None, **kwargs)
torch.nn.utils.prune.custom_from_mask(module, name, mask)
torch.nn.utils.prune.remove(module, name)
torch.nn.utils.prune.is_pruned(module)
torch.nn.utils.weight_norm(module, name='weight', dim=0)
torch.nn.utils.remove_weight_norm(module, name='weight')
torch.nn.utils.spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None)
torch.nn.utils.remove_spectral_norm(module, name='weight')
torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)
torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)
torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0.0)
torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True)
torch.nn.Flatten(start_dim=1, end_dim=-1)
torch.nn.Unflatten(dim, unflattened_size)
torch.nn.modules.lazy.LazyModuleMixin(*args, **kwargs)
torch.Tensor.requires_grad_(_input_tensor, requires_grad=True)
torch.Tensor.gather(_input_tensor, dim, index)
torch.Tensor.square_(_input_tensor)
torch.Tensor.xlogy_(_input_tensor, other)
torch.Tensor.clip(_input_tensor, min=None, max=None)
torch.Tensor.round(_input_tensor)
torch.Tensor.argsort(_input_tensor, dim=-1, descending=False)
torch.Tensor.fill_diagonal_(_input_tensor, fill_value, wrap=False)
torch.Tensor.index_fill(_input_tensor, dim, index, value)
torch.Tensor.acosh(_input_tensor)
torch.Tensor.asinh(_input_tensor)
torch.Tensor.size(_input_tensor, dim=None)
torch.Tensor.unbind(_input_tensor, dim=0)
torch.Tensor.kthvalue(_input_tensor, k, dim=None, keepdim=False)
torch.Tensor.le_(_input_tensor, other)
torch.Tensor.angle(_input_tensor)
torch.Tensor.vsplit(_input_tensor, split_size_or_sections)
torch.Tensor.pinverse(_input_tensor)
torch.Tensor.cholesky(_input_tensor, upper=False)
torch.Tensor.div_(_input_tensor, value, *, rounding_mode=None)
torch.Tensor.pow(_input_tensor, exponent)
torch.Tensor.logical_not_(_input_tensor)
torch.Tensor.storage(_input_tensor)
torch.Tensor.smm(_input_tensor, mat)
torch.Tensor.scatter_add_(_input_tensor, dim, index, src)
torch.Tensor.scatter_(_input_tensor, dim, index, src, reduce=None)
torch.Tensor.arcsinh_(_input_tensor)
torch.Tensor.new_ones(_input_tensor, size, dtype=None, device=None, requires_grad=False)
torch.Tensor.mul_(_input_tensor, value)
torch.Tensor.diff(_input_tensor, n=1, dim=-1, prepend=None, append=None)
torch.Tensor.conj_physical_(_input_tensor)
torch.Tensor.atanh(_input_tensor)
torch.Tensor.igammac(_input_tensor, other)
torch.Tensor.to(_input_tensor, *args, **kwargs)
torch.Tensor.flip(_input_tensor, dims)
torch.Tensor.transpose_(_input_tensor, dim0, dim1)
torch.Tensor.acos(_input_tensor)
torch.Tensor.erfc(_input_tensor)
torch.Tensor.solve(_input_tensor, A)
torch.Tensor.sum(_input_tensor, dim=None, keepdim=False, dtype=None)
torch.Tensor.scatter_add(_input_tensor, dim, index, src)
torch.Tensor.tile(_input_tensor, dims)
torch.Tensor.arcsin(_input_tensor)
torch.Tensor.nextafter(_input_tensor, other)
torch.Tensor.matrix_power(_input_tensor, n)
torch.Tensor.erf_(_input_tensor)
torch.Tensor.lcm(_input_tensor, other)
torch.Tensor.logical_and(_input_tensor, other)
torch.Tensor.max(_input_tensor, dim=None, keepdim=False)
torch.Tensor.roll(_input_tensor, shifts, dims)
torch.Tensor.sinh(_input_tensor)
torch.Tensor.stride(_input_tensor, dim)
torch.Tensor.is_signed(_input_tensor)
torch.Tensor.log(_input_tensor)
torch.Tensor.lt_(_input_tensor, other)
torch.Tensor.arctanh(_input_tensor)
torch.Tensor.eq_(_input_tensor, other)
torch.Tensor.dot(_input_tensor, other)
torch.Tensor.gt_(_input_tensor, other)
torch.Tensor.isneginf(_input_tensor)
torch.Tensor.storage_offset(_input_tensor)
torch.Tensor.logaddexp2(_input_tensor, other)
torch.Tensor.cumprod(_input_tensor, dim, dtype=None)
torch.Tensor.positive(_input_tensor)
torch.Tensor.frac_(_input_tensor)
torch.Tensor.neg_(_input_tensor)
torch.Tensor.ravel(_input_tensor)
torch.Tensor.bitwise_xor_(_input_tensor, other)
torch.Tensor.cov(_input_tensor, *, correction=1, fweights=None, aweights=None)
torch.Tensor.corrcoef(_input_tensor)
torch.Tensor.symeig(_input_tensor, eigenvectors=False, upper=True)
torch.Tensor.bitwise_not_(_input_tensor)
torch.Tensor.logsumexp(_input_tensor, dim, keepdim=False)
torch.Tensor.where(_input_tensor, condition, y)
torch.Tensor.fmod_(_input_tensor, divisor)
torch.Tensor.cross(_input_tensor, other, dim=-1)
torch.Tensor.addbmm(_input_tensor, batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.all(_input_tensor, dim=None, keepdim=False)
torch.Tensor.less_equal_(_input_tensor, other)
torch.Tensor.arccos(_input_tensor)
torch.Tensor.less_equal(_input_tensor, other)
torch.Tensor.frexp(_input_tensor, input)
torch.Tensor.unfold(_input_tensor, dimension, size, step)
torch.Tensor.repeat(_input_tensor, *sizes)
torch.Tensor.rot90(_input_tensor, k, dims)
torch.Tensor.q_per_channel_axis(_input_tensor)
torch.Tensor.numel(_input_tensor)
torch.Tensor.unique(_input_tensor, sorted=True, return_inverse=False, return_counts=False, dim=None)
torch.Tensor.reshape_as(_input_tensor, other)
torch.Tensor.divide_(_input_tensor, value, *, rounding_mode=None)
torch.Tensor.asinh_(_input_tensor)
torch.Tensor.movedim(_input_tensor, source, destination)
torch.Tensor.sum_to_size(_input_tensor, *size)
torch.Tensor.to_mkldnn(_input_tensor)
torch.Tensor.sub_(_input_tensor, other, *, alpha=1)
torch.Tensor.bernoulli(_input_tensor, *, generator=None)
torch.Tensor.cholesky_solve(_input_tensor, input2, upper=False)
torch.Tensor.item(_input_tensor)
torch.Tensor.copysign(_input_tensor, other)
torch.Tensor.cosh(_input_tensor)
torch.Tensor.abs(_input_tensor)
torch.Tensor.sparse_dim(_input_tensor)
torch.Tensor.floor_divide(_input_tensor, value)
torch.Tensor.gcd(_input_tensor, other)
torch.Tensor.triangular_solve(_input_tensor, A, upper=True, transpose=False, unitriangular=False)
torch.Tensor.nanquantile(_input_tensor, q, dim=None, keepdim=False)
torch.Tensor.logdet(_input_tensor)
torch.Tensor.rsqrt_(_input_tensor)
torch.Tensor.swapaxes(_input_tensor, axis0, axis1)
torch.Tensor.sub(_input_tensor, other, *, alpha=1)
torch.Tensor.swapdims(_input_tensor, dim0, dim1)
torch.Tensor.qr(_input_tensor, some=True)
torch.Tensor.resolve_conj(_input_tensor)
torch.Tensor.nonzero(_input_tensor, as_tuple=False)
torch.Tensor.index_fill_(_input_tensor, dim, index, value)
torch.Tensor.outer(_input_tensor, vec2)
torch.Tensor.fmax(_input_tensor, other)
torch.Tensor.norm(_input_tensor, p='fro', dim=None, keepdim=False, dtype=None)
torch.Tensor.addr(_input_tensor, vec1, vec2, *, beta=1, alpha=1)
torch.Tensor.permute(_input_tensor, *dims)
torch.Tensor.as_subclass(_input_tensor, cls)
torch.Tensor.igammac_(_input_tensor, other)
torch.Tensor.erfinv_(_input_tensor)
torch.Tensor.topk(_input_tensor, k, dim=None, largest=True, sorted=True)
torch.Tensor.cos_(_input_tensor)
torch.Tensor.narrow_copy(_input_tensor, dimension, start, length)
torch.Tensor.unsqueeze(_input_tensor, dim)
torch.Tensor.hsplit(_input_tensor, split_size_or_sections)
torch.Tensor.ndimension(_input_tensor)
torch.Tensor.isnan(_input_tensor)
torch.Tensor.greater_equal_(_input_tensor, other)
torch.Tensor.xlogy(_input_tensor, other)
torch.Tensor.tanh(_input_tensor)
torch.Tensor.fmin(_input_tensor, other)
torch.Tensor.add(_input_tensor, other, *, alpha=1)
torch.Tensor.lt(_input_tensor, other)
torch.Tensor.new_tensor(_input_tensor, data, dtype=None, device=None, requires_grad=False)
torch.Tensor.expand(_input_tensor, *sizes)
torch.Tensor.sspaddmm(_input_tensor, mat1, mat2, *, beta=1, alpha=1)
torch.Tensor.flipud(_input_tensor)
torch.Tensor.index_add(_input_tensor, dim, index, tensor2)
torch.Tensor.not_equal(_input_tensor, other)
torch.Tensor.floor_(_input_tensor)
torch.Tensor.ormqr(_input_tensor, input2, input3, left=True, transpose=False)
torch.Tensor.inner(_input_tensor, other)
torch.Tensor.lu_solve(_input_tensor, LU_data, LU_pivots)
torch.Tensor.bitwise_and(_input_tensor, other)
torch.Tensor.any(_input_tensor, dim=None, keepdim=False)
torch.Tensor.renorm(_input_tensor, p, dim, maxnorm)
torch.Tensor.index_put_(_input_tensor, indices, values, accumulate=False)
torch.Tensor.cumsum(_input_tensor, dim, dtype=None)
torch.Tensor.isreal(_input_tensor)
torch.Tensor.isclose(_input_tensor, other, rtol=1e-05, atol=1e-08, equal_nan=False)
torch.Tensor.fill_(_input_tensor, value)
torch.Tensor.logical_xor_(_input_tensor, other)
torch.Tensor.clamp_(_input_tensor, min=None, max=None)
torch.Tensor.remainder(_input_tensor, divisor)
torch.Tensor.sgn_(_input_tensor)
torch.Tensor.normal_(_input_tensor, mean=0, std=1, *, generator=None)
torch.Tensor.fix(_input_tensor)
torch.Tensor.baddbmm_(_input_tensor, batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.tolist(_input_tensor)
torch.Tensor.i0(_input_tensor)
torch.Tensor.int(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.logaddexp(_input_tensor, other)
torch.Tensor.ne(_input_tensor, other)
torch.Tensor.q_scale(_input_tensor)
torch.Tensor.log1p_(_input_tensor)
torch.Tensor.logit(_input_tensor)
torch.Tensor.byte(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.diagonal(_input_tensor, offset=0, dim1=0, dim2=1)
torch.Tensor.put_(_input_tensor, index, source, accumulate=False)
torch.Tensor.sparse_mask(_input_tensor, mask)
torch.Tensor.log10(_input_tensor)
torch.Tensor.take_along_dim(_input_tensor, indices, dim)
torch.Tensor.cauchy_(_input_tensor, median=0, sigma=1, *, generator=None)
torch.Tensor.lt(_input_tensor, other)
torch.Tensor.sign(_input_tensor)
torch.Tensor.acos_(_input_tensor)
torch.Tensor.stft(_input_tensor, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=None, return_complex=None)
torch.Tensor.det(_input_tensor)
torch.Tensor.lgamma(_input_tensor)
torch.Tensor.lu(_input_tensor, pivot=True, get_infos=False)
torch.Tensor.erfc_(_input_tensor)
torch.Tensor.half(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.istft(_input_tensor, n_fft, hop_length=None, win_length=None, window=None, center=True, normalized=False, onesided=None, length=None, return_complex=False)
torch.Tensor.bitwise_right_shift_(_input_tensor, other)
torch.Tensor.less_(_input_tensor, other)
torch.Tensor.bernoulli_(_input_tensor, p=0.5, *, generator=None)
torch.Tensor.cumprod_(_input_tensor, dim, dtype=None)
torch.Tensor.abs_(_input_tensor)
torch.Tensor.map_(_input_tensor, tensor, callable
torch.Tensor.random_(_input_tensor, from=0, to=None, *, generator=None)
torch.Tensor.rsqrt(_input_tensor)
torch.Tensor.index_copy_(_input_tensor, dim, index, tensor)
torch.Tensor.ne_(_input_tensor, other)
torch.Tensor.as_strided(_input_tensor, size, stride, storage_offset=0)
torch.Tensor.exp(_input_tensor)
torch.Tensor.amax(_input_tensor, dim=None, keepdim=False)
torch.Tensor.bitwise_left_shift_(_input_tensor, other)
torch.Tensor.addbmm_(_input_tensor, batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.lgamma_(_input_tensor)
torch.Tensor.triu(_input_tensor, diagonal=0)
torch.Tensor.bitwise_not(_input_tensor)
torch.Tensor.subtract_(_input_tensor, other, *, alpha=1)
torch.Tensor.nanmedian(_input_tensor, dim=None, keepdim=False)
torch.Tensor.char(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.masked_fill(_input_tensor, mask, value)
torch.Tensor.dsplit(_input_tensor, split_size_or_sections)
torch.Tensor.arctan(_input_tensor)
torch.Tensor.deg2rad(_input_tensor)
torch.Tensor.type_as(_input_tensor, tensor)
torch.Tensor.bitwise_left_shift(_input_tensor, other)
torch.Tensor.conj_physical(_input_tensor)
torch.Tensor.sin_(_input_tensor)
torch.Tensor.ceil_(_input_tensor)
torch.Tensor.mode(_input_tensor, dim=None, keepdim=False)
torch.Tensor.isinf(_input_tensor)
torch.Tensor.record_stream(_input_tensor, stream
torch.Tensor.values(_input_tensor)
torch.Tensor.sgn(_input_tensor)
torch.Tensor.logit_(_input_tensor)
torch.Tensor.ceil(_input_tensor)
torch.Tensor.dense_dim(_input_tensor)
torch.Tensor.absolute(_input_tensor)
torch.Tensor.geqrf(_input_tensor)
torch.Tensor.sort(_input_tensor, dim=-1, descending=False)
torch.Tensor.new_zeros(_input_tensor, size, dtype=None, device=None, requires_grad=False)
torch.Tensor.pin_memory(_input_tensor)
torch.Tensor.matrix_exp(_input_tensor)
torch.Tensor.cumsum_(_input_tensor, dim, dtype=None)
torch.Tensor.renorm_(_input_tensor, p, dim, maxnorm)
torch.Tensor.sinc_(_input_tensor)
torch.Tensor.div(_input_tensor, value, *, rounding_mode=None)
torch.Tensor.fmod(_input_tensor, divisor)
torch.Tensor.quantile(_input_tensor, q, dim=None, keepdim=False)
torch.Tensor.split(_input_tensor, split_size, dim=0)
torch.Tensor.log2(_input_tensor)
torch.Tensor.exp_(_input_tensor)
torch.Tensor.greater_(_input_tensor, other)
torch.Tensor.expand_as(_input_tensor, other)
torch.Tensor.long(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.data_ptr(_input_tensor)
torch.Tensor.squeeze(_input_tensor, dim=None)
torch.Tensor.digamma_(_input_tensor)
torch.Tensor.index_add_(_input_tensor, dim, index, tensor, *, alpha=1)
torch.Tensor.bool(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.scatter(_input_tensor, dim, index, src)
torch.Tensor.nansum(_input_tensor, dim=None, keepdim=False, dtype=None)
torch.Tensor.hardshrink(_input_tensor, lambd=0.5)
torch.Tensor.greater_equal(_input_tensor, other)
torch.Tensor.mvlgamma(_input_tensor, p)
torch.Tensor.nan_to_num(_input_tensor, nan=0.0, posinf=None, neginf=None)
torch.Tensor.double(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.dim(_input_tensor)
torch.Tensor.squeeze_(_input_tensor, dim=None)
torch.Tensor.mm(_input_tensor, mat2)
torch.Tensor.conj(_input_tensor)
torch.Tensor.subtract(_input_tensor, other, *, alpha=1)
torch.Tensor.log_normal_(_input_tensor, mean=1, std=2, *, generator=None
torch.Tensor.resize_as_(_input_tensor, tensor, memory_format=torch.contiguous_format)
torch.Tensor.add_(_input_tensor, other, *, alpha=1)
torch.Tensor.to_sparse(_input_tensor, sparseDims)
torch.Tensor.masked_scatter_(_input_tensor, mask, source
torch.Tensor.logical_or_(_input_tensor, other)
torch.Tensor.dequantize(_input_tensor)
torch.Tensor.bitwise_right_shift(_input_tensor, other)
torch.Tensor.arctan_(_input_tensor)
torch.Tensor.broadcast_to(_input_tensor, shape)
torch.Tensor.exponential_(_input_tensor, lambd=1, *, generator=None)
torch.Tensor.acosh(_input_tensor)
torch.Tensor.expm1(_input_tensor)
torch.Tensor.view(_input_tensor, *shape)
torch.Tensor.index_put(_input_tensor, indices, values, accumulate=False)
torch.Tensor.erf(_input_tensor)
torch.Tensor.is_inference(_input_tensor)
torch.Tensor.isfinite(_input_tensor)
torch.Tensor.tensor_split(_input_tensor, indices_or_sections, dim=0)
torch.Tensor.erfinv(_input_tensor)
torch.Tensor.addr_(_input_tensor, vec1, vec2, *, beta=1, alpha=1)
torch.Tensor.neg(_input_tensor)
torch.Tensor.argmin(_input_tensor, dim=None, keepdim=False)
torch.Tensor.hypot_(_input_tensor, other)
torch.Tensor.bitwise_and_(_input_tensor, other)
torch.Tensor.float_power(_input_tensor, exponent)
torch.Tensor.eig(_input_tensor, eigenvectors=False)
torch.Tensor.float_power_(_input_tensor, exponent)
torch.Tensor.sigmoid_(_input_tensor)
torch.Tensor.ge_(_input_tensor, other)
torch.Tensor.addmv(_input_tensor, mat, vec, *, beta=1, alpha=1)
torch.Tensor.hypot(_input_tensor, other)
torch.Tensor.std(_input_tensor, dim, unbiased=True, keepdim=False)
torch.Tensor.frac(_input_tensor)
torch.Tensor.log1p(_input_tensor)
torch.Tensor.get_device(_input_tensor)
torch.Tensor.short(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.prod(_input_tensor, dim=None, keepdim=False, dtype=None)
torch.Tensor.retain_grad(_input_tensor)
torch.Tensor.sigmoid(_input_tensor)
torch.Tensor.isposinf(_input_tensor)
torch.Tensor.arccos_(_input_tensor)
torch.Tensor.atan(_input_tensor)
torch.Tensor.fliplr(_input_tensor)
torch.Tensor.clip_(_input_tensor, min=None, max=None)
torch.Tensor.lerp(_input_tensor, end, weight)
torch.Tensor.tan_(_input_tensor)
torch.Tensor.ger(_input_tensor, vec2)
torch.Tensor.true_divide(_input_tensor, value)
torch.Tensor.diagflat(_input_tensor, offset=0)
torch.Tensor.heaviside(_input_tensor, values)
torch.Tensor.trunc_(_input_tensor)
torch.Tensor.new_empty(_input_tensor, size, dtype=None, device=None, requires_grad=False)
torch.Tensor.true_divide_(_input_tensor, value)
torch.Tensor.logical_xor(_input_tensor, other)
torch.Tensor.addcmul_(_input_tensor, tensor1, tensor2, *, value=1)
torch.Tensor.gt(_input_tensor, other)
torch.Tensor.type(_input_tensor, dtype=None, non_blocking=False, **kwargs)
torch.Tensor.copy_(_input_tensor, src, non_blocking=False)
torch.Tensor.rad2deg(_input_tensor)
torch.Tensor.floor(_input_tensor)
torch.Tensor.min(_input_tensor, dim=None, keepdim=False)
torch.Tensor.index_copy(_input_tensor, dim, index, tensor2)
torch.Tensor.nextafter_(_input_tensor, other)
torch.Tensor.t(_input_tensor)
torch.Tensor.divide(_input_tensor, value, *, rounding_mode=None)
torch.Tensor.asin_(_input_tensor)
torch.Tensor.maximum(_input_tensor, other)
torch.Tensor.q_per_channel_zero_points(_input_tensor)
torch.Tensor.sqrt(_input_tensor)
torch.Tensor.histogram(_input_tensor, input, bins, *, range=None, weight=None, density=False)
torch.Tensor.qscheme(_input_tensor)
torch.Tensor.atanh_(_input_tensor, other)
torch.Tensor.bitwise_xor(_input_tensor, other)
torch.Tensor.msort(_input_tensor)
torch.Tensor.multiply_(_input_tensor, value)
torch.Tensor.cos(_input_tensor)
torch.Tensor.q_zero_point(_input_tensor)
torch.Tensor.set_(_input_tensor, source=None, storage_offset=0, size=None, stride=None)
torch.Tensor.orgqr(_input_tensor, input2)
torch.Tensor.element_size(_input_tensor)
torch.Tensor.minimum(_input_tensor, other)
torch.Tensor.vdot(_input_tensor, other)
torch.Tensor.addcmul(_input_tensor, tensor1, tensor2, *, value=1)
torch.Tensor.pow_(_input_tensor, exponent)
torch.Tensor.lcm_(_input_tensor, other)
torch.Tensor.cummin(_input_tensor, dim)
torch.Tensor.inverse(_input_tensor)
torch.Tensor.negative_(_input_tensor)
torch.Tensor.transpose(_input_tensor, dim0, dim1)
torch.Tensor.histc(_input_tensor, bins=100, min=0, max=0)
torch.Tensor.arcsinh(_input_tensor)
torch.Tensor.igamma(_input_tensor, other)
torch.Tensor.acosh_(_input_tensor)
torch.Tensor.bmm(_input_tensor, batch2)
torch.Tensor.floor_divide_(_input_tensor, value)
torch.Tensor.dist(_input_tensor, other, p=2)
torch.Tensor.logical_or(_input_tensor, other)
torch.Tensor.clamp(_input_tensor, min=None, max=None)
torch.Tensor.multiply(_input_tensor, value)
torch.Tensor.bitwise_or_(_input_tensor, other)
torch.Tensor.indices(_input_tensor)
torch.Tensor.arcsin_(_input_tensor)
torch.Tensor.index_select(_input_tensor, dim, index)
torch.Tensor.logical_not(_input_tensor)
torch.Tensor.acosh_(_input_tensor)
torch.Tensor.diag(_input_tensor, diagonal=0)
torch.Tensor.is_floating_point(_input_tensor)
torch.Tensor.svd(_input_tensor, some=True, compute_uv=True)
torch.Tensor.ldexp_(_input_tensor, other)
torch.Tensor.take(_input_tensor, indices)
torch.Tensor.argmax(_input_tensor, dim=None, keepdim=False)
torch.Tensor.trace(_input_tensor)
torch.Tensor.unique_consecutive(_input_tensor, return_inverse=False, return_counts=False, dim=None)
torch.Tensor.asin(_input_tensor)
torch.Tensor.tril(_input_tensor, diagonal=0)
torch.Tensor.bincount(_input_tensor, weights=None, minlength=0)
torch.Tensor.is_complex(_input_tensor)
torch.Tensor.trunc(_input_tensor)
torch.Tensor.float(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.t_(_input_tensor)
torch.Tensor.diag_embed(_input_tensor, offset=0, dim1=-2, dim2=-1)
torch.Tensor.reciprocal_(_input_tensor)
torch.Tensor.cummax(_input_tensor, dim)
torch.Tensor.flatten(_input_tensor, start_dim=0, end_dim=-1)
torch.Tensor.addmm(_input_tensor, mat1, mat2, *, beta=1, alpha=1)
torch.Tensor.aminmax(_input_tensor, *, dim=None, keepdim=False)
torch.Tensor.triu_(_input_tensor, diagonal=0)
torch.Tensor.int_repr(_input_tensor)
torch.Tensor.nan_to_num_(_input_tensor, nan=0.0, posinf=None, neginf=None)
torch.Tensor.sign_(_input_tensor)
torch.Tensor.equal(_input_tensor, other)
torch.Tensor.new_full(_input_tensor, size, fill_value, dtype=None, device=None, requires_grad=False)
torch.Tensor.tan(_input_tensor)
torch.Tensor.cosh_(_input_tensor)
torch.Tensor.lstsq(_input_tensor, A)
torch.Tensor.lerp_(_input_tensor, end, weight)
torch.Tensor.atan_(_input_tensor)
torch.Tensor.addmm_(_input_tensor, mat1, mat2, *, beta=1, alpha=1)
torch.Tensor.cpu(_input_tensor, memory_format=torch.preserve_format)
torch.Tensor.logcumsumexp(_input_tensor, dim)
torch.Tensor.addmv_(_input_tensor, mat, vec, *, beta=1, alpha=1)
torch.Tensor.not_equal_(_input_tensor, other)
torch.Tensor.sin(_input_tensor)
torch.Tensor.tril_(_input_tensor, diagonal=0)
torch.Tensor.uniform_(_input_tensor, from=0, to=1)
torch.Tensor.sinh_(_input_tensor)
torch.Tensor.Alias for :meth:`~Tensor.dim(_input_tensor)
torch.Tensor.bitwise_or(_input_tensor, other)
torch.Tensor.reshape(_input_tensor, *shape)
torch.Tensor.amin(_input_tensor, dim=None, keepdim=False)
torch.Tensor.nanmean(_input_tensor, dim=None, keepdim=False, *, dtype=None)
torch.Tensor.mean(_input_tensor, dim=None, keepdim=False, *, dtype=None)
torch.Tensor.is_conj(_input_tensor)
torch.Tensor.copysign_(_input_tensor, other)
torch.Tensor.gcd_(_input_tensor, other)
torch.Tensor.negative(_input_tensor)
torch.Tensor.view_as(_input_tensor, other)
torch.Tensor.atan2_(_input_tensor, other)
torch.Tensor.masked_fill_(_input_tensor, mask, value
torch.Tensor.eq(_input_tensor, other)
torch.Tensor.resolve_neg(_input_tensor)
torch.Tensor.signbit(_input_tensor)
torch.Tensor.ldexp(_input_tensor, other)
torch.Tensor.resize_(_input_tensor, *sizes, memory_format=torch.contiguous_format)
torch.Tensor.contiguous(_input_tensor, memory_format=torch.contiguous_format)
torch.Tensor.sinc(_input_tensor)
torch.Tensor.is_set_to(_input_tensor, tensor)
torch.Tensor.is_contiguous(_input_tensor, memory_format=torch.contiguous_format)
torch.Tensor.absolute_(_input_tensor)
torch.Tensor.storage_type(_input_tensor)
torch.Tensor.log10_(_input_tensor)
torch.Tensor.mv(_input_tensor, vec)
torch.Tensor.allclose(_input_tensor, other, rtol=1e-05, atol=1e-08, equal_nan=False)
torch.Tensor.select(_input_tensor, dim, index)
torch.Tensor.unsqueeze_(_input_tensor, dim)
torch.Tensor.clone(_input_tensor, *, memory_format=torch.preserve_format)
torch.Tensor.cholesky_inverse(_input_tensor, upper=False)
torch.Tensor.expm1_(_input_tensor)
torch.Tensor.reciprocal(_input_tensor)
torch.Tensor.addcdiv(_input_tensor, tensor1, tensor2, *, value=1)
torch.Tensor.digamma(_input_tensor)
torch.Tensor.square(_input_tensor)
torch.Tensor.arctanh_(_input_tensor, other)
torch.Tensor.q_per_channel_scales(_input_tensor)
torch.Tensor.chunk(_input_tensor, chunks, dim=0)
torch.Tensor.geometric_(_input_tensor, p, *, generator=None)
torch.Tensor.atan2(_input_tensor, other)
torch.Tensor.moveaxis(_input_tensor, source, destination)
torch.Tensor.baddbmm(_input_tensor, batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.narrow(_input_tensor, dimension, start, length)
torch.Tensor.remainder_(_input_tensor, divisor)
torch.Tensor.logical_and_(_input_tensor, other)
torch.Tensor.le(_input_tensor, other)
torch.Tensor.nelement(_input_tensor)
torch.Tensor.masked_scatter(_input_tensor, mask, tensor)
torch.Tensor.slogdet(_input_tensor)
torch.Tensor.polygamma_(_input_tensor, n)
torch.Tensor.fix_(_input_tensor)
torch.Tensor.ge(_input_tensor, other)
torch.Tensor.greater(_input_tensor, other)
torch.Tensor.matmul(_input_tensor, tensor2)
torch.Tensor.addcdiv_(_input_tensor, tensor1, tensor2, *, value=1)
torch.Tensor.log_(_input_tensor)
torch.Tensor.i0_(_input_tensor)
torch.Tensor.multinomial(_input_tensor, num_samples, replacement=False, *, generator=None)
torch.Tensor.polygamma(_input_tensor, n)
torch.Tensor.log2_(_input_tensor)
torch.Tensor.zero_(_input_tensor)
torch.Tensor.numpy(_input_tensor)
torch.Tensor.count_nonzero(_input_tensor, dim=None)
torch.Tensor.round_(_input_tensor)
torch.Tensor.tanh_(_input_tensor)
torch.Tensor.igamma_(_input_tensor, other)
torch.Tensor.masked_select(_input_tensor, mask)
torch.Tensor.repeat_interleave(_input_tensor, repeats, dim=None, *, output_size=None)
torch.Tensor.sqrt_(_input_tensor)
torch.Tensor.median(_input_tensor, dim=None, keepdim=False)
torch.Tensor.var(_input_tensor, dim, unbiased=True, keepdim=False)
torch.Tensor.mul(_input_tensor, value)
torch.Tensor.apply_(_input_tensor, callable)
torch.Tensor.mvlgamma_(_input_tensor, p)
torch.Tensor.arccosh(_input_tensor)
torch.nn.GELU()
torch.nn.Tanh()
torch.nn.Sigmoid()
torch.nn.LogSigmoid()
torch.nn.Tanhshrink()
torch.nn.Softsign()
torch.trapezoid(y, x=None, *, dx=None, dim=- 1)
torch.orgqr(input, tau)
torch.aminmax(input, *, dim=None, keepdim=False, out=None)
torch.nanmean(input, dim=None, keepdim=False, *, dtype=None, out=None)
torch.bitwise_left_shift(input, other, *, out=None)
torch.bitwise_right_shift(input, other, *, out=None)
torch.conj_physical(input, *, out=None)
torch.corrcoef(input)
torch.cov(input, *, correction=1, fweights=None, aweights=None)
torch.frexp(input, *, out=None)
torch.histogram(input, bins, *, range=None, weight=None, density=False, out=None)
torch.Tensor.less(_input_tensor, other)
torch.permute(input, dims)
torch.positive(input)
torch.resolve_conj(input)
torch.resolve_neg(input)
torch.sinc(input, *, out=None)
torch.smm(input, mat)
torch.sspaddmm(input, mat1, mat2, *, beta=1, alpha=1, out=None)
torch.take_along_dim(input, indices, dim, *, out=None)
torch.nn.Softmax2d()
torch.nn.parameter.UninitializedParameter(requires_grad=True, device=None, dtype=None)
torch.nn.functional.mish(input, inplace=False)
torch.fft.fft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.QUInt4x2Storage(*args, **kwargs)
torch.nn.init.constant_(tensor, val)
torch.fx.Interpreter(module, garbage_collect_values=True)
torch.futures.Future(*, devices=None)
torch.distributed.elastic.rendezvous.RendezvousHandler()
torch.nn.utils.prune.Identity(module, name)
torch.utils.checkpoint.checkpoint_sequential(functions, segments, input, **kwargs)
torch.special.erfinv(input, *, out=None)
torch.distributions.transforms.StickBreakingTransform(cache_size=0)
torch.jit.load(f, map_location=None, _extra_files=None)
torch.utils.benchmark.Measurement(number_per_run, raw_times, task_spec, metadata=None)
torch.special.i0(input, *, out=None)
torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler(rdzv_impl)
torch.CharStorage(*args, **kwargs)
torch.utils.dlpack.to_dlpack(tensor)
torch.distributions.transforms.ExpTransform(cache_size=0)
torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.nn.LazyBatchNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.nn.parameter.Parameter(data=None, requires_grad=True)
torch.BoolStorage(*args, **kwargs)
torch.linalg.eigvals(A, *, out=None)
torch.hub.set_dir(d)
torch.distributions.half_normal.HalfNormal(scale, validate_args=None)
torch.inference_mode(mode=True)
torch.distributed.elastic.multiprocessing.errors.ProcessFailure(local_rank, pid, exitcode, error_file)
torch.special.gammainc(input, other, *, out=None)
torch.distributed.elastic.events.get_logging_handler(destination='null')
torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler()
torch.special.logit(input, eps=None, *, out=None)
torch.random.seed()
torch.Tensor.ndim(_input_tensor)
torch.distributed.new_group(ranks=None, backend=None, pg_options=None)
torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=None, rank=None, shuffle=True, seed=0, drop_last=False)
torch.distributed.reduce_scatter_multigpu(output_tensor_list, input_tensor_lists, group=None, async_op=False)
torch.distributions.von_mises.VonMises(loc, concentration, validate_args=None)
torch.jit.ScriptFunction()
torch.distributed.elastic.events.api.EventSource(value)
torch.distributions.poisson.Poisson(rate, validate_args=None)
torch.utils.data.TensorDataset(*tensors)
torch.utils.data.get_worker_info()
torch.distributed.is_initialized()
torch.nn.utils.skip_init(module_cls, *args, **kwargs)
torch.random.manual_seed(seed)
torch.QUInt8Storage(*args, **kwargs)
torch.linalg.lstsq(A, B, rcond=None, *, driver=None)
torch.distributions.exp_family.ExponentialFamily(batch_shape=[], event_shape=[], validate_args=None)
torch.sparse_csr_tensor(crow_indices, col_indices, values, size=None, *, dtype=None, device=None, requires_grad=False)
torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
torch.Tensor.detach_(_input_tensor, )
torch.distributed.elastic.metrics.api.NullMetricHandler()
torch.nn.init.ones_(tensor)
torch.distributed.FileStore()
torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.create_backend(params)
torch.utils.data.ConcatDataset(datasets)
torch.overrides.is_tensor_like(inp)
torch.distributed.elastic.events.record(event, destination='null')
torch.utils.checkpoint.checkpoint(function, *args, **kwargs)
torch.distributed.all_gather_object(object_list, obj, group=None)
torch.hub.list(github, force_reload=False, skip_validation=False)
torch.distributed.elastic.rendezvous.RendezvousStateError()
torch.gradient(input, *, spacing=1, dim=None, edge_order=1)
torch.fft.rfft(input, n=None, dim=-1, norm=None, *, out=None)
torch.special.gammaln(input, *, out=None)
torch.distributed.elastic.multiprocessing.errors.ChildFailedError(name, failures)
torch.count_nonzero(input, dim=None)
torch.distributed.elastic.agent.server.Worker(local_rank, global_rank=-1, role_rank=-1, world_size=-1, role_world_size=-1)
torch.utils.data.BatchSampler(sampler, batch_size, drop_last)
torch.distributed.get_rank(group=None)
torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None)
torch.Tensor.share_memory_(_input_tensor, )
torch.utils.cpp_extension.BuildExtension(*args, **kwargs)
torch.hub.load_state_dict_from_url(url, model_dir=None, map_location=None, progress=True, check_hash=False, file_name=None)
torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)
torch.jit.freeze(mod, preserved_attrs=None, optimize_numerics=True)
torch.distributed.elastic.timer.expires(after, scope=None, client=None)
torch.distributed.broadcast(tensor, src, group=None, async_op=False)
torch.optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))
torch.distributions.constraint_registry.ConstraintRegistry()
torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)
torch.special.polygamma(n, input, *, out=None)
torch.onnx.register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)
torch.distributions.transforms.PowerTransform(exponent, cache_size=0)
torch.distributed.elastic.metrics.configure(handler, group=None)
torch.package.EmptyMatchError()
torch.IntStorage(*args, **kwargs)
torch.overrides.is_tensor_method_or_property(func)
torch.fx.Transformer(module)
torch.distributions.uniform.Uniform(low, high, validate_args=None)
torch.nn.utils.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.optim.NAdam(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, momentum_decay=0.004)
torch.distributed.irecv(tensor, src=None, group=None, tag=0)
torch.distributed.scatter(tensor, scatter_list=None, src=0, group=None, async_op=False)
torch.distributed.elastic.multiprocessing.api.SubprocessContext(name, entrypoint, args, envs, stdouts, stderrs, tee_stdouts, tee_stderrs, error_files)
torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.create_backend(params)
torch.BFloat16Storage(*args, **kwargs)
torch.nn.init.xavier_uniform_(tensor, gain=1.0)
torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)
torch.special.expm1(input, *, out=None)
torch.special.i1(input, *, out=None)
torch.distributed.elastic.timer.configure(timer_client)
torch.DoubleStorage(*args, **kwargs)
torch.nn.init.sparse_(tensor, sparsity, std=0.01)
torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
torch.fft.rfft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)
torch.cumulative_trapezoid(y, x=None, *, dx=None, dim=-1)
torch.distributed.reduce_multigpu(tensor_list, dst, group=None, async_op=False, dst_tensor=0)
torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)
torch.nn.utils.parametrize.register_parametrization(module, tensor_name, parametrization, *, unsafe=False)
torch.hub.load(repo_or_dir, model, *args, source='github', force_reload=False, verbose=True, skip_validation=False, **kwargs)
torch.no_grad()
torch.distributed.is_torchelastic_launched()
torch.nn.LazyBatchNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.jit.unused(fn)
torch.Tensor.arccosh_(_input_tensor, )
torch.onnx.select_model_mode_for_export(model, mode)
torch.linalg.eigvalsh(A, UPLO='L', *, out=None)
torch.distributed.get_world_size(group=None)
torch.ShortStorage(*args, **kwargs)
torch.distributions.chi2.Chi2(df, validate_args=None)
torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None)
torch.utils.data.SequentialSampler(data_source)
torch.special.psi(input, *, out=None)
torch.distributions.transforms.StackTransform(tseq, dim=0, cache_size=0)
torch.utils.cpp_extension.verify_ninja_availability()
torch.futures.collect_all(futures)
torch.fft.ihfft(input, n=None, dim=-1, norm=None, *, out=None)
torch.Tensor.is_sparse(_input_tensor, )
torch.utils.benchmark.CallgrindStats(task_spec, number_per_run, built_with_debug_symbols, baseline_inclusive_stats, baseline_exclusive_stats, stmt_inclusive_stats, stmt_exclusive_stats, stmt_callgrind_out)
torch.nn.utils.parametrize.cached()
torch.Tensor.is_leaf(_input_tensor, )
torch.distributed.elastic.multiprocessing.errors.record(fn, error_handler=None)
torch.Tensor.grad(_input_tensor, )
torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)
torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.3333333333333333, end_factor=1.0, total_iters=5, last_epoch=-1, verbose=False)
torch.profiler.ProfilerAction(value)
torch.jit.isinstance(obj, target_type)
torch.utils.model_zoo.load_url(url, model_dir=None, map_location=None, progress=True, check_hash=False, file_name=None)
torch.hub.help(github, model, force_reload=False, skip_validation=False)
torch.utils.dlpack.from_dlpack(ext_tensor)
torch.distributed.elastic.timer.LocalTimerServer(mp_queue, max_interval=60, daemon=True)
torch.nn.init.zeros_(tensor)
torch.distributed.elastic.multiprocessing.api.PContext(name, entrypoint, args, envs, stdouts, stderrs, tee_stdouts, tee_stderrs, error_files)
torch.testing.make_tensor(shape, device, dtype, *, low=None, high=None, requires_grad=False, noncontiguous=False, exclude_zero=False)
torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)
torch.nn.utils.parametrizations.spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None)
torch.Tensor.bfloat16(_input_tensor, memory_format=torch.preserve_format)
torch.nn.GLU(dim=-1)
torch.fft.rfftn(input, s=None, dim=None, norm=None, *, out=None)
torch.distributed.elastic.agent.server.WorkerGroup(spec)
torch.FloatStorage(*args, **kwargs)
torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=None, async_op=False)
torch.QInt32Storage(*args, **kwargs)
torch.distributed.optim.ZeroRedundancyOptimizer(params, optimizer_class, process_group=None, parameters_as_bucket_view=False, overlap_with_ddp=False, **defaults)
torch.sparse.softmax(input, dim, dtype=None)
torch.fx.Graph(owning_module=None, tracer_cls=None)
torch.distributed.send(tensor, dst, group=None, tag=0)
torch.nn.FeatureAlphaDropout(p=0.5, inplace=False)
torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.constraints.Constraint()
torch.sparse.addmm(mat, mat1, mat2, beta=1.0, alpha=1.0)
torch.distributed.gather_object(obj, object_gather_list=None, dst=0, group=None)
torch.nn.LazyBatchNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None, generator=None)
torch.Tensor.real(_input_tensor, )
torch.optim.Optimizer(params, defaults)
torch.jit.fork(func, *args, **kwargs)
torch.special.erf(input, *, out=None)
torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)
torch.utils.cpp_extension.load(name, sources, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, is_standalone=False, keep_intermediates=True)
torch.fx.symbolic_trace(root, concrete_args=None, enable_cpatching=False)
torch.profiler.schedule(*, wait, warmup, active, repeat=0, skip_first=0)
torch.nn.init.normal_(tensor, mean=0.0, std=1.0)
torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')
torch.utils.data.SubsetRandomSampler(indices, generator=None)
torch.distributed.elastic.rendezvous.etcd_server.EtcdServer(data_dir=None)
torch.distributed.elastic.agent.server.SimpleElasticAgent(spec, exit_barrier_timeout=300)
torch.Tensor.backward(_input_tensor, gradient=None, retain_graph=None, create_graph=False, inputs=None)
torch.special.zeta(input, other, *, out=None)
torch.distributed.elastic.rendezvous.RendezvousConnectionError()
torch.hub.get_dir()
torch.fx.GraphModule(*args, **kwargs)
torch.fft.fftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=None, steps_per_epoch=None, pct_start=0.3, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, three_phase=False, last_epoch=-1, verbose=False)
torch.ComplexFloatStorage(*args, **kwargs)
torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)
torch.special.exp2(input, *, out=None)
torch.fft.fftn(input, s=None, dim=None, norm=None, *, out=None)
torch.isin(elements, test_elements, *, assume_unique=False, invert=False)
torch.distributed.TCPStore()
torch.distributed.elastic.rendezvous.RendezvousParameters(backend, endpoint, run_id, min_nodes, max_nodes, **kwargs)
torch.special.expit(input, *, out=None)
torch.jit.ignore(drop=False, **kwargs)
torch.special.gammaincc(input, other, *, out=None)
torch.distributed.elastic.metrics.api.ConsoleMetricHandler()
torch.profiler.ProfilerActivity()
torch.overrides.has_torch_function()
torch.jit.optimize_for_inference(mod)
torch.sparse.mm(mat1, mat2)
torch.special.digamma(input, *, out=None)
torch.special.log_softmax(input, dim, *, dtype=None)
torch.distributions.continuous_bernoulli.ContinuousBernoulli(probs=None, logits=None, lims=(0.499, 0.501), validate_args=None)
torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler)
torch.nn.init.uniform_(tensor, a=0.0, b=1.0)
torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)
torch.hspmm(mat1, mat2, *, out=None)
torch.utils.data.Sampler(data_source)
torch.utils.tensorboard.writer.SummaryWriter(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')
torch.distributions.transforms.AbsTransform(cache_size=0)
torch.ComplexDoubleStorage(*args, **kwargs)
torch.nn.utils.parametrize.is_parametrized(module, tensor_name=None)
torch.distributed.elastic.timer.LocalTimerClient(mp_queue)
torch.overrides.get_overridable_functions()
torch.utils.cpp_extension.is_ninja_available()
torch.sparse.log_softmax(input, dim, dtype=None)
torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)
torch.distributed.HashStore()
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1, verbose=False)
torch.nn.init.xavier_normal_(tensor, gain=1.0)
torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)
torch.distributed.all_to_all(output_tensor_list, input_tensor_list, group=None, async_op=False)
torch.Tensor.is_shared(_input_tensor, )
torch.distributed.is_mpi_available()
torch.utils.data.Subset(dataset, indices)
torch.distributed.elastic.rendezvous.dynamic_rendezvous.create_handler(store, backend, params)
torch.Tensor.cuda(_input_tensor, device=None, non_blocking=False, memory_format=torch.preserve_format)
torch.distributed.elastic.rendezvous.RendezvousError()
torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry()
torch.distributed.reduce_op()
torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1, verbose=False)
torch.fft.irfft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.package.Directory(name, is_dir)
torch.nn.functional.fractional_max_pool2d(*args, **kwargs)
torch.nn.modules.module.register_module_full_backward_hook(hook)
torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend(client, run_id, key_prefix=None, ttl=None)
torch.Tensor.is_pinned(_input_tensor, )
torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False)
torch.distributed.gather(tensor, gather_list=None, dst=0, group=None, async_op=False)
torch.profiler.profile(*, activities=None, schedule=None, on_trace_ready=None, record_shapes=False, profile_memory=False, with_stack=False, with_flops=False, with_modules=False, use_cuda=None)
torch.Tensor.is_cuda(_input_tensor, )
torch.futures.wait_all(futures)
torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)
torch.distributed.elastic.rendezvous.RendezvousTimeoutError()
torch.distributions.mixture_same_family.MixtureSameFamily(mixture_distribution, component_distribution, validate_args=None)
torch.distributed.elastic.rendezvous.etcd_store.EtcdStore(etcd_client, etcd_store_prefix, timeout=None)
torch.distributed.elastic.multiprocessing.errors.ErrorHandler()
torch.distributed.is_available()
torch.Tensor.register_hook(_input_tensor, hook)
torch.distributed.Backend(name)
torch.special.ndtr(input, *, out=None)
torch.nn.functional.huber_loss(input, target, reduction='mean', delta=1.0)
torch.fft.hfft(input, n=None, dim=-1, norm=None, *, out=None)
torch.utils.mobile_optimizer.optimize_for_mobile(script_module, optimization_blocklist=None, preserved_methods=None, backend='CPU')
torch.quantized_max_pool1d(input, kernel_size, stride=[], padding=0, dilation=1, ceil_mode=False)
torch.distributed.elastic.metrics.api.MetricHandler()
torch.special.ndtri(input, *, out=None)
torch.distributed.Store.wait(*args, **kwargs)
torch.sparse.sum(input, dim=None, dtype=None)
torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')
torch.distributed.elastic.agent.server.ElasticAgent()
torch.nn.Module()
torch.distributions.distribution.Distribution(batch_shape=[], event_shape=[], validate_args=None)
torch.distributed.recv(tensor, src=None, group=None, tag=0)
torch.fx.Proxy(node, tracer=None)
torch.nn.utils.parametrize.ParametrizationList(modules, original, unsafe=False)
torch.distributed.elastic.metrics.prof(fn=None, group='torchelastic')
torch.fx.replace_pattern(gm, pattern, replacement)
torch.QInt8Storage(*args, **kwargs)
torch.distributions.transforms.CorrCholeskyTransform(cache_size=0)
torch.optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
torch.special.round(input, *, out=None)
torch.nn.parameter.UninitializedBuffer(requires_grad=False, device=None, dtype=None)
torch.HalfStorage(*args, **kwargs)
torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)
torch.nn.utils.parametrize.remove_parametrizations(module, tensor_name, leave_parametrized=True)
torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)
torch.distributed.Store()
torch.fft.ifft(input, n=None, dim=-1, norm=None, *, out=None)
torch.nn.functional.group_norm(input, num_groups, weight=None, bias=None, eps=1e-05)
torch.nn.init.dirac_(tensor, groups=1)
torch.optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)
torch.random.initial_seed()
torch.nn.utils.parametrizations.orthogonal(module, name='weight', orthogonal_map=None, *, use_trivialization=True)
torch.utils.benchmark.FunctionCounts(_data, inclusive, truncate_rows=True, _linewidth=None)
torch.distributed.broadcast_multigpu(tensor_list, src, group=None, async_op=False, src_tensor=0)
torch.is_inference_mode_enabled()
torch.nn.init.calculate_gain(nonlinearity, param=None)
torch.jit.script_if_tracing(fn)
torch.Tensor.is_quantized(_input_tensor, )
torch.distributed.elastic.timer.TimerRequest(worker_id, scope_id, expiration_time)
torch.special.multigammaln(input, p, *, out=None)
torch.hub.download_url_to_file(url, dst, hash_prefix=None, progress=True)
torch.dsplit(input, indices_or_sections)
torch.distributions.transforms.ReshapeTransform(in_shape, out_shape, cache_size=0)
torch.optim.LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)
torch.nn.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.jit.save(m, f, _extra_files=None)
torch.distributed.scatter_object_list(scatter_object_output_list, scatter_object_input_list, src=0, group=None)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)
torch.package.PackagingError(dependency_graph)
torch.special.i0e(input, *, out=None)
torch.distributions.transforms.SigmoidTransform(cache_size=0)
torch.linalg.cond(A, p=None, *, out=None)
torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.transforms.IndependentTransform(base_transform, reinterpreted_batch_ndims, cache_size=0)
torch.special.entr(input, *, out=None)
torch.linalg.svd(A, full_matrices=True, *, out=None)
torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout(join=None, last_call=None, close=None, heartbeat=None)
torch.distributed.is_nccl_available()
torch.fft.fft(input, n=None, dim=-1, norm=None, *, out=None)
torch.optim.RAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)
torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers, milestones, last_epoch=-1, verbose=False)
torch.fx.wrap(fn_or_name)
torch.is_warn_always_enabled()
torch.fft.ifftn(input, s=None, dim=None, norm=None, *, out=None)
torch.distributed.elastic.agent.server.WorkerState(value)
torch.nn.ReflectionPad3d(padding)
torch.jit.ScriptModule()
torch.distributed.get_backend(group=None)
torch.distributed.PrefixStore()
torch.distributions.transforms.SoftmaxTransform(cache_size=0)
torch.special.erfcx(input, *, out=None)
torch.nn.init.eye_(tensor)
torch.enable_grad()
torch.overrides.handle_torch_function(public_api, relevant_args, *args, **kwargs)
torch.distributed.elastic.timer.TimerServer(request_queue, max_interval, daemon=True)
torch.distributions.normal.Normal(loc, scale, validate_args=None)
torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent(spec, start_method='spawn', exit_barrier_timeout=300, log_dir=None)
torch.utils.data.IterableDataset(*args, **kwds)
torch.distributed.algorithms.JoinHook()
torch.special.xlogy(input, other, *, out=None)
torch.distributed.isend(tensor, dst, group=None, tag=0)
torch.distributed.algorithms.Join(joinables, enable=True, throw_on_early_termination=False, **kwargs)
torch.utils.cpp_extension.include_paths(cuda=False)
torch.fx.Node(graph, name, op, target, args, kwargs, return_type=None)
torch.utils.cpp_extension.load_inline(name, cpp_sources, cuda_sources=None, functions=None, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, with_pytorch_error_handling=True, keep_intermediates=True)
torch.quantized_batch_norm(input, weight=None, bias=None, mean, var, eps, output_scale, output_zero_point)
torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices')
torch.distributed.algorithms.Joinable()
torch.quantized_max_pool2d(input, kernel_size, stride=[], padding=0, dilation=1, ceil_mode=False)
torch.utils.data.ChainDataset(datasets)
torch.fft.ifft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)
torch.overrides.get_testing_overrides()
torch.jit.wait(future)
torch.Tensor.detach(_input_tensor, )
torch.utils.cpp_extension.CppExtension(name, sources, *args, **kwargs)
torch.testing.assert_close(actual, expected, *, allow_subclasses=True, rtol=None, atol=None, equal_nan=False, check_device=True, check_dtype=True, check_stride=False, check_is_coalesced=True, msg=None)
torch.vsplit(input, indices_or_sections)
torch.LongStorage(*args, **kwargs)
torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)
torch.optim.lr_scheduler.ChainedScheduler(schedulers)
torch.distributions.lkj_cholesky.LKJCholesky(dim, concentration=1.0, validate_args=None)
torch.overrides.wrap_torch_function(dispatcher)
torch.nn.HuberLoss(reduction='mean', delta=1.0)
torch.nn.functional.fractional_max_pool3d(*args, **kwargs)
torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)
torch.special.erfc(input, *, out=None)
torch.distributions.kl.register_kl(type_p, type_q)
torch.distributed.ReduceOp()
torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend()
torch.is_conj(input)
torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)
torch.special.logsumexp(input, dim, keepdim=False, *, out=None)
torch.special.i1e(input, *, out=None)
torch.distributed.elastic.multiprocessing.api.MultiprocessContext(name, entrypoint, args, envs, stdouts, stderrs, tee_stdouts, tee_stderrs, error_files, start_method)
torch.fft.irfftn(input, s=None, dim=None, norm=None, *, out=None)
torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)
torch.nn.utils.prune.BasePruningMethod()
torch.random.set_rng_state(new_state)
torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)
torch.distributed.broadcast_object_list(object_list, src=0, group=None, device=None)
torch.profiler.tensorboard_trace_handler(dir_name, worker_name=None, use_gzip=False)
torch.nn.functional.gaussian_nll_loss(input, target, var, full=False, eps=1e-06, reduction='mean')
torch.random.get_rng_state()
torch.hsplit(input, indices_or_sections)
torch.distributions.transforms.ComposeTransform(parts, cache_size=0)
torch.nn.LazyInstanceNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend(store, run_id)
torch.linalg.svdvals(A, *, out=None)
torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)
torch.distributed.elastic.metrics.put_metric(metric_name, metric_value, metric_group='torchelastic')
torch.nn.FractionalMaxPool3d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None)
torch.fft.fftshift(input, dim=None)
torch.overrides.get_ignored_functions()
torch.distributions.laplace.Laplace(loc, scale, validate_args=None)
torch.distributed.monitored_barrier(group=None, timeout=None, wait_all_ranks=False)
torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)
torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)
torch.ByteStorage(*args, **kwargs)
torch.onnx.is_in_onnx_export()
torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1, verbose=False)
torch.Tensor.retains_grad(_input_tensor, )
torch.is_grad_enabled()
torch.distributions.exponential.Exponential(rate, validate_args=None)
torch.special.sinc(input, *, out=None)
torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)
torch.nn.init.orthogonal_(tensor, gain=1)
torch.Tensor.device(_input_tensor, )
torch.Tensor.is_meta(_input_tensor, )
torch.fft.ifftshift(input, dim=None)
torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)
torch.distributions.kl.kl_divergence(p, q)
torch.nn.Mish(inplace=False)
torch.distributed.elastic.rendezvous.RendezvousClosedError()
torch.distributed.barrier(group=None, async_op=False, device_ids=None)
torch.jit.script(obj, optimize=None, _frames_up=0, _rcb=None, example_inputs=None)
torch.fft.irfft(input, n=None, dim=-1, norm=None, *, out=None)
torch.optim.lr_scheduler.ConstantLR(optimizer, factor=0.3333333333333333, total_iters=5, last_epoch=-1, verbose=False)
torch.utils.cpp_extension.CUDAExtension(name, sources, *args, **kwargs)
torch.optim.ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)
torch.special.log1p(input, *, out=None)
torch.nn.LazyInstanceNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.distributed.all_gather(tensor_list, tensor, group=None, async_op=False)
torch.Tensor.imag(_input_tensor, )
torch.frombuffer(buffer, *, dtype, count=-1, offset=0, requires_grad=False)
torch.distributions.transforms.TanhTransform(cache_size=0)
torch.distributions.kumaraswamy.Kumaraswamy(concentration1, concentration0, validate_args=None)
torch.set_warn_always(b)
torch.distributions.transforms.Transform(cache_size=0)
torch.Tensor.requires_grad(_input_tensor, )
torch.fft.rfftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.jit.annotate(the_type, the_value)
torch.utils.data.Dataset(*args, **kwds)
torch.special.xlog1py(input, other, *, out=None)